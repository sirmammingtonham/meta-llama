{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import EvalDatasetWrapper, ICLCollator, preprocess_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/yeeb/.cache/huggingface/datasets/json/default-96676ccee0c43a59/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "Found cached dataset json (/Users/yeeb/.cache/huggingface/datasets/json/default-8b0cc3f6e2fb8516/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    }
   ],
   "source": [
    "train = datasets.load_dataset('json', data_files='../data/baseline_train/abstract_narrative_understanding.json', split='train')\n",
    "test = datasets.load_dataset('json', data_files='../data/baseline_test/crash_blossom.json', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': \"In what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: Ralph had a clothing store and sales had peaked. He looked at his sales data and noticed one demographic wasn't buying his clothes. So, Ralph started a rumor that he wouldn't sell his clothes to them and when word got out that group of people started purchasing his clothes just to spite him. Now, Ralph enjoys taking money from all demographic groups.\\nThis narrative is a good illustration of the following proverb:\",\n",
       " 'idx': 463,\n",
       " 'targets': ['All publicity is good publicity'],\n",
       " 'multiple_choice_scores': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " 'true_idx': 2063,\n",
       " 'is_generated': False,\n",
       " 'multiple_choice_targets': ['He who laughs last laughs longest',\n",
       "  'Honey catches more flies than vinegar',\n",
       "  'Build a better mousetrap and the world will beat a path to your doorLink to proverb',\n",
       "  'All publicity is good publicity',\n",
       "  'Revenge is a dish best served cold',\n",
       "  'Give credit where credit is due',\n",
       "  \"It's the squeaky wheel that gets the grease\",\n",
       "  \"What's sauce for the goose is sauce for the gander\",\n",
       "  'Strike while the iron is hot',\n",
       "  'Flattery will get you nowhere']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 'Identify the part of speech (verb, adjective, noun, or preposition) of the specified word in the following headlines.\\n\\nIn the following sentence, what part of speech is watch? Sentence: Watch batteries while you wait\\nA:',\n",
       " 'idx': 13,\n",
       " 'targets': ['noun'],\n",
       " 'multiple_choice_scores': [0, 0, 1, 0],\n",
       " 'true_idx': 13,\n",
       " 'is_generated': False,\n",
       " 'multiple_choice_targets': ['verb', 'adjective', 'noun', 'preposition']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/yeeb/.cache/huggingface/datasets/json/default-96676ccee0c43a59/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ff2376a2b0057b13_*_of_00008.arrow\n",
      "Loading cached processed dataset at /Users/yeeb/.cache/huggingface/datasets/json/default-8b0cc3f6e2fb8516/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ad266f0c897c866b_*_of_00008.arrow\n"
     ]
    }
   ],
   "source": [
    "train_processed = preprocess_dataset(train, tokenizer)\n",
    "test_processed = preprocess_dataset(test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "from typing import List, Dict, Any, Union\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ICLCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    k_examples: int = 16\n",
    "    max_length: int = 2048\n",
    "    return_tensors: str = \"pt\"\n",
    "    for_eval: bool = False\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        * creates batches for in context/few shot learning\n",
    "        * length of [features] should be (k_examples * batch_size)\n",
    "        * if for_eval create a labels field\n",
    "        \"\"\"\n",
    "        batch = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "        if self.for_eval:\n",
    "            # if collation for evaluation, features is a List[List[Dict[str, Any]]]\n",
    "            # where the inner list contains our k_examples, so flatten it\n",
    "            features = list(itertools.chain.from_iterable(features))\n",
    "\n",
    "        for i in range(0, len(features), self.k_examples):\n",
    "            batch[\"input_ids\"].append(\n",
    "                list(\n",
    "                    itertools.chain.from_iterable(\n",
    "                        example[\"input_ids\"]\n",
    "                        for example in features[i : i + self.k_examples]\n",
    "                    )\n",
    "                )[: self.max_length]\n",
    "            )\n",
    "            batch[\"attention_mask\"].append(\n",
    "                list(\n",
    "                    itertools.chain.from_iterable(\n",
    "                        example[\"attention_mask\"]\n",
    "                        for example in features[i : i + self.k_examples]\n",
    "                    )\n",
    "                )[: self.max_length]\n",
    "            )\n",
    "            batch[\"token_type_ids\"].append(\n",
    "                list(\n",
    "                    itertools.chain.from_iterable(\n",
    "                        example[\"token_type_ids\"]\n",
    "                        for example in features[i : i + self.k_examples]\n",
    "                    )\n",
    "                )[: self.max_length]\n",
    "            )\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            batch,\n",
    "            padding=\"longest\",\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "\n",
    "        if self.for_eval:\n",
    "            batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
    "            batch[\"labels\"] *= batch[\"token_type_ids\"]\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvalDatasetWrapper(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Simple Dataset wrapper that returns k_examples-1 random\n",
    "    examples from the training set for each evaluation example\n",
    "    \"\"\"\n",
    "\n",
    "    train_dataset: datasets.Dataset\n",
    "    eval_dataset: datasets.Dataset\n",
    "    k_examples: int = 16\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eval_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        random_examples = np.random.randint(\n",
    "            0, len(self.train_dataset), size=(self.k_examples - 1,)\n",
    "        )\n",
    "        examples = [self.train_dataset[i.item()] for i in random_examples]\n",
    "        for x in examples:\n",
    "            # ignore label mask for the examples, we only care about the last one\n",
    "            x[\"token_type_ids\"] = [0] * len(x[\"token_type_ids\"])\n",
    "\n",
    "        target = self.eval_dataset[index]\n",
    "\n",
    "        label_start = target[\"token_type_ids\"].index(1)\n",
    "        target[\"input_ids\"] = target[\"input_ids\"][:label_start]\n",
    "        target[\"attention_mask\"] = target[\"attention_mask\"][:label_start]\n",
    "        target[\"token_type_ids\"] = target[\"token_type_ids\"][:label_start]\n",
    "\n",
    "        # remove the label from the target (cheating if we dont do this lol)\n",
    "        # target[\"input_ids\"] = [\n",
    "        #     target[\"input_ids\"][i]\n",
    "        #     for i, label in enumerate(target[\"token_type_ids\"])\n",
    "        #     if not label\n",
    "        # ]\n",
    "        # target[\"attention_mask\"] = [\n",
    "        #     target[\"attention_mask\"][i]\n",
    "        #     for i, label in enumerate(target[\"token_type_ids\"])\n",
    "        #     if not label\n",
    "        # ]\n",
    "        # target[\"token_type_ids\"] = [\n",
    "        #     label for label in target[\"token_type_ids\"] if not label\n",
    "        # ]\n",
    "\n",
    "        return examples + [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_dataset = EvalDatasetWrapper(train_processed, test_processed, k_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = ICLCollator(tokenizer, k_examples=3, for_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(wrapped_dataset, batch_size=3, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: Herbert is man of words but sometimes he tells stories that are unimaginable. We thought that he was always lying. He once said about a two-legged dog which everyone thought was a lie. Then Herbert actually showed up with the dog and we were shocked.\\nThis narrative is a good illustration of the following proverb: \\n\\nSeeing is believing \\n\\n\\nIn what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: Robbie delighted in telling people stories about his wealthy background even though he actually came from a poor home.  In college, his new roommate confronted Robbie about his true background.  His roommate told Robbie he also told people false stories about his rich parents.\\nThis narrative is a good illustration of the following proverb: \\n\\nIt takes a thief to catch a thief \\n\\n\\nIdentify the part of speech (verb, adjective, noun, or preposition) of the specified word in the following headlines.\\n\\nIn the following sentence, what part of speech is barbecue? Sentence: Lawmen from Honduras barbecue guests\\nA: \\n\\n<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ex['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: Herbert is man of words but sometimes he tells stories that are unimaginable. We thought that he was always lying. He once said about a two-legged dog which everyone thought was a lie. Then Herbert actually showed up with the dog and we were shocked.\\nThis narrative is a good illustration of the following proverb: \\n\\nSeeing is believing \\n\\n\\nIn what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: Robbie delighted in telling people stories about his wealthy background even though he actually came from a poor home.  In college, his new roommate confronted Robbie about his true background.  His roommate told Robbie he also told people false stories about his rich parents.\\nThis narrative is a good illustration of the following proverb: \\n\\nIt takes a thief to catch a thief \\n\\n\\nIdentify the part of speech (verb, adjective, noun, or preposition) of the specified word in the following headlines.\\n\\nIn the following sentence, what part of speech is barbecue? Sentence: Lawmen from Honduras barbecue guests\\nA: \\n\\n<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ex['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In what follows, we provide short narratives, each of which illustrates a common proverb. \n",
      "Narrative: Herbert is man of words but sometimes he tells stories that are unimaginable. We thought that he was always lying. He once said about a two-legged dog which everyone thought was a lie. Then Herbert actually showed up with the dog and we were shocked.\n",
      "This narrative is a good illustration of the following proverb: \n",
      "\n",
      "Seeing is believing \n",
      "\n",
      "\n",
      "In what follows, we provide short narratives, each of which illustrates a common proverb. \n",
      "Narrative: Robbie delighted in telling people stories about his wealthy background even though he actually came from a poor home.  In college, his new roommate confronted Robbie about his true background.  His roommate told Robbie he also told people false stories about his rich parents.\n",
      "This narrative is a good illustration of the following proverb: \n",
      "\n",
      "It takes a thief to catch a thief \n",
      "\n",
      "\n",
      "Identify the part of speech (verb, adjective, noun, or preposition) of the specified word in the following headlines.\n",
      "\n",
      "In the following sentence, what part of speech is barbecue? Sentence: Lawmen from Honduras barbecue guests\n",
      "A: \n",
      "\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(ex['input_ids'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
